# Algorithms {#algorithms}
In this section, we will discuss each algorithms used in details; for a more thorough explanation and elegant proof for these algorithms, please refer to _What Is a Computer and What Can It Do?_ by Thomas Oâ€™Connell. 

First, the standard <span style="font-variant:small-caps;">MaxValDP</span> algorithm (the vanilla flavor that we are all too familiar to hate) is really the most standard way we know to solve Maximum 0-1 Knapsack problem. It attempts to construct in bottom-up manner a table of dimension $n \times B$, where each cell $Cell[i][j]$ gives the maximum value that can be achieved using item 1 to $i$ with budget $j$. After the computation process, the bottom right-most cell of the table gives us the optimal value. The running time for this algorithm is $\Theta(nB)$. 

<span style="font-variant:small-caps;">Greedy</span> refers to the greedy 2-approximation algorithm that tackles the Maximum Fractional Knapsack version. As such, firstly, we sort the item in ascending order based on value/cost ratio. We continuously add items to the knapsack until it is full. There might be a case where we can actually just take the item with maximum value and use it instead. Here, we need to make an assumption that the budget is higher than the maximum cost of any item--_we have enforced this condition while generating the knapsack problem instance so we can safely make this assumption_. This algorithm's running time depends on the running time of the sorting step and thus, it is $\Theta(n\log{n})$.

<span style="font-variant:small-caps;">MinCostDP</span> deals with the MinCost version of the Maximum 0-1 Knapsack problem. Instead of looking for the set of item whose total costs does not reach the budget and whose value is the maximum, this version looks for set of item whose total values does not fall below the target value and whose budget is the minimum. As such, it employs the same strategy as <span style="font-variant:small-caps;">MaxValDP</span>. First, it constructs in bottom-up manner a table of dimension $n \times nv_{max}$; hence the columns of this table lists out all possible values that different subsets of item can take. Each cell of the table, $Cell[i][j]$ gives the minimum budget required using item 1 to $i$ to achieve target value $j$. After the computation process, we scan through the bottom row of the table and find the cell with maximum column index whose value equals to the budget. The running time for this algorithm is $\Theta(n^2v_{max})$. As we can see, by changing the original problem slightly, we now put the burden of the running on the maximum value rather than the budget, like in <span style="font-variant:small-caps;">MaxValDP</span>. 

<span style="font-variant:small-caps;">FPTAS</span> attempts to reduce the running time of <span style="font-variant:small-caps;">MinCostDP</span> at the cost of accuracy. It scales the items' values down by a factor of $\frac{\epsilon \times v_{max}}{n}$, where $\epsilon$ stands for the percentage of error allowed, and performs truncation to obtain a new integer value for each item. It then runs <span style="font-variant:small-caps;">MinCostDP</span> and the obtained result is then re-scaled. As such, the running time for this algorithm is $\Theta(n^3\frac{1}{\epsilon})$. For this particular assignment, we want to set $\epsilon$ to 0.5, i.e. this should make <span style="font-variant:small-caps;">FPTAS</span> comparable to <span style="font-variant:small-caps;">Greedy</span> (2-approximation), thus we can compare the performance of these 2 algorithms. 

Here, we should note that since other than <span style="font-variant:small-caps;">Greedy</span>, other algorithms construct large table to perform dynamic programming. As such, this might set a limit on the size of input we use. As mentioned before in section \@ref(resdis), this puts an upper bound on the number of items used to 700. And yet, we will face this plaguing issue once again while performing the second experiment with 3SAT reduction, which will be discussed in the next section.